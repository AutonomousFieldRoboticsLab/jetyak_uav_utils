diff --git a/cfg/behaviors_M.yaml b/cfg/behaviors_M.yaml
index ac1cafe..f33c094 100644
--- a/cfg/behaviors_M.yaml
+++ b/cfg/behaviors_M.yaml
@@ -24,17 +24,17 @@ follow_w: 0
 #
 # Land Parameters
 #
-land_x: -0.87
-land_y: -0.05
-land_z: -0.05 # this should be .1-.2m over the tag to allow the uav to maneuver
+land_x: -0.9
+land_y: -0.09
+land_z: 0 # this should be .1-.2m over the tag to allow the uav to maneuver
 land_w: 0
 
 land_velMag: .1
-land_xTopThresh: .07
+land_xTopThresh: .05
 land_yTopThresh: .05
-land_xBottomThresh: .12
-land_yBottomThresh: .12
-land_bottom: -0.15
+land_xBottomThresh: .075
+land_yBottomThresh: .075
+land_bottom: -0.2
 land_top: .1
 land_angleThresh: .25
 
@@ -51,5 +51,5 @@ return_finalHeight: 4
 return_downRadius: 1
 return_settleRadius: .5
 return_tagTime: 1
-return_tagLossThresh: 3
+return_tagLossThresh: 1
 return_maxVel: 3.0
diff --git a/cfg/fullMetal.xml b/cfg/fullMetal.xml
index b07b54a..b3fd1f2 100644
--- a/cfg/fullMetal.xml
+++ b/cfg/fullMetal.xml
@@ -14,28 +14,28 @@
 		<corner x="7.05" y="6.45" z="0" />
 	</marker>
 	<marker index="3" status="1">
-		<corner x="12.3" y="-23" z="100.3" />
-		<corner x="64.1" y="-23" z="100.3" />
-		<corner x="64.1" y="-23" z="48.5" />
-		<corner x="12.3" y="-23" z="48.5" />
+		<corner x="14.3" y="-22.5" z="99.3" />
+		<corner x="66.1" y="-22.5" z="99.3" />
+		<corner x="66.1" y="-22.5" z="47.5" />
+		<corner x="14.3" y="-22.5" z="47.5" />
 	</marker>
 	<marker index="4" status="1">
-		<corner x="12.3" y="-23" z="161.3" />
-		<corner x="64.1" y="-23" z="161.3" />
-		<corner x="64.1" y="-23" z="109.5" />
-		<corner x="12.3" y="-23" z="109.5" />
+		<corner x="14.3" y="-22.5" z="160.3" />
+		<corner x="66.1" y="-22.5" z="160.3" />
+		<corner x="66.1" y="-22.5" z="108.5" />
+		<corner x="14.3" y="-22.5" z="108.5" />
 	</marker>
 	<marker index="5" status="1">
-		<corner x="2.8" y="-23" z="109.5" />
-		<corner x="-49" y="-23" z="109.5" />
-		<corner x="-49" y="-23" z="161.3" />
-		<corner x="2.8" y="-23" z="161.3" />
+		<corner x="4.8" y="-22.5" z="108.5" />
+		<corner x="-47" y="-22.5" z="108.5" />
+		<corner x="-47" y="-22.5" z="160.3" />
+		<corner x="4.8" y="-22.5" z="160.3" />
 	</marker>
 	<marker index="6" status="1">
-		<corner x="2.8" y="-23" z="48.5" />
-		<corner x="-49" y="-23" z="48.5" />
-		<corner x="-49" y="-23" z="100.3" />
-		<corner x="2.8" y="-23" z="100.3" />
+		<corner x="4.8" y="-22.5" z="47.5" />
+		<corner x="-47" y="-22.5" z="47.5" />
+		<corner x="-47" y="-22.5" z="99.3" />
+		<corner x="4.8" y="-22.5" z="99.3" />
 	</marker>
 	
 	
diff --git a/cfg/generalK.txt b/cfg/generalK.txt
index d1a2bfe..ab8be6f 100644
--- a/cfg/generalK.txt
+++ b/cfg/generalK.txt
@@ -8,5 +8,5 @@
 11 2 0.129
 3 3 0.604
 6 3 0.361
-9 4 0.523
-12 4 0.332
+9 4 0.440
+12 4 0.249
diff --git a/cfg/generalK_mod.txt b/cfg/generalK_mod.txt
deleted file mode 100644
index 63f5b18..0000000
--- a/cfg/generalK_mod.txt
+++ /dev/null
@@ -1,12 +0,0 @@
-2 1 -0.814
-5 1 -0.614
-7 1 0.955
-10 1 0.102
-1 2 0.888
-4 2 0.676
-8 2 1.101
-11 2 0.129
-3 3 0.604
-6 3 0.361
-9 4 0.440
-12 4 0.249
diff --git a/cfg/gimbal_cam.yaml b/cfg/gimbal_cam.yaml
index 4b49651..e449a0e 100644
--- a/cfg/gimbal_cam.yaml
+++ b/cfg/gimbal_cam.yaml
@@ -13,8 +13,7 @@ toggle_track_btn: 3
 
 Kp: .003
 Kd: 0
-velLimitY: .4
-velLimitP: .75
+velLimit: .75
 
 # dji_camera config
 camera_info_url: package://dji_gimbal_cam/cfg/zenmuse_z3.yaml
diff --git a/cfg/landK (copy).txt b/cfg/landK (copy).txt
deleted file mode 100644
index 78e2aab..0000000
--- a/cfg/landK (copy).txt	
+++ /dev/null
@@ -1,12 +0,0 @@
-2 1 -0.643
-5 1 -0.575
-7 1 0.920
-10 1 0.102
-1 2 0.644
-4 2 0.577
-8 2 0.926
-11 2 0.105
-3 3 0.604
-6 3 0.361
-9 4 0.440
-12 4 0.249
diff --git a/include/jetyak_uav_utils/behaviors.h b/include/jetyak_uav_utils/behaviors.h
index bae771f..5d9fd42 100644
--- a/include/jetyak_uav_utils/behaviors.h
+++ b/include/jetyak_uav_utils/behaviors.h
@@ -26,7 +26,7 @@ SOFTWARE.
  * Base behavioral controller for the uav
  * Manages the high level methods of the system.
  * Sends commands to the UAV
- * implements a joystick override
+ * implements a joystick ovveride
  * implements a safety controller for if the drone is too close to an object
  * Listens to topic to determine when to switch modes
  * 
diff --git a/msg/ObservedState.msg b/msg/ObservedState.msg
index f94248f..ce81a4f 100644
--- a/msg/ObservedState.msg
+++ b/msg/ObservedState.msg
@@ -8,8 +8,5 @@ geometry_msgs/Vector3 boat_p
 geometry_msgs/Vector3 boat_pdot
 float64 heading
 
-geometry_msgs/Vector3 gps_offset
-float64 heading_offset
-
 # ENU Origin coordinate [lon,lat,alt]
 geometry_msgs/Vector3 origin
diff --git a/scripts/nodes/filter/data_point.py b/scripts/nodes/filter/data_point.py
new file mode 100755
index 0000000..16bae47
--- /dev/null
+++ b/scripts/nodes/filter/data_point.py
@@ -0,0 +1,55 @@
+"""
+MIT License
+
+Copyright(c) 2018 Brennan Cain and Michail Kalaitzakis(Unmanned Systems and Robotics Lab, University of South Carolina, USA)
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files(the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
+
+Author: Michail Kalaitzakis
+
+"""
+
+class DataPoint:
+	"""
+		Sensor measurements handle to store all the desired data in a standard way
+		Handles tag position data and imu data. Imu data should be integrated to represent velocities
+	"""
+	
+	def __init__(self):
+		self.ID        = None
+		self.timeStamp = None
+		self.Z         = None
+
+	def setID(self, dataID):
+		self.ID = dataID
+
+	def setZ(self, sensorMeasurement):
+		self.Z = sensorMeasurement
+
+	def setTime(self, measurementTime):
+		self.timeStamp = measurementTime
+	
+	def getID(self):
+		return self.ID
+
+	def getZ(self):
+		return self.Z
+
+	def getTime(self):
+		return self.timeStamp
diff --git a/scripts/nodes/filter/filter_node.py b/scripts/nodes/filter/filter_node.py
index c8a4548..14b5184 100755
--- a/scripts/nodes/filter/filter_node.py
+++ b/scripts/nodes/filter/filter_node.py
@@ -36,14 +36,13 @@ from sensor_msgs.msg import Imu, NavSatFix
 from geometry_msgs.msg import PoseStamped, Vector3Stamped, QuaternionStamped
 from jetyak_uav_utils.msg import ObservedState
 
-from sensor import Sensor
+from data_point import DataPoint
 from fusion_ekf import FusionEKF
 from gps_utils import GPS_utils
 from quaternion import Quaternion
 from quaternion import quatMultiply
 from quaternion import quatInverse
 from quaternion import quat2rpy
-from setupSensors import setupSensors
 
 import threading
 
@@ -56,11 +55,14 @@ class FilterNode():
 		self.myENU = GPS_utils()
 		self.originSet = False
 
+		# Create handle for last tag
+		self.lastTag = DataPoint()
+
 		# Set rate of publisher
 		self.rate = 50.0
 
 		# Number of states
-		n = 15
+		n = 24
 
 		# Initial State Transition Matrix
 		F = np.asmatrix(np.eye(n))
@@ -68,17 +70,64 @@ class FilterNode():
 		# Initial Process Matrix
 		P = np.asmatrix(1.0e3 * np.eye(n))
 
-		# Process Noise Level
-		N = 1e-3
+		# Transition Matrix for Tag measurements
+		self.Htag = np.matrix(np.zeros((4, n)))
+		self.Htag[0:3,   0:3] = np.matrix(-1 * np.eye(3))
+		self.Htag[0:3, 14:17] = np.matrix(np.eye(3))
+		self.Htag[0:3, 20:23] = np.matrix(-1 * np.eye(3))
+		self.Htag[3,      19] =  1
+		self.Htag[3,      23] = -1
+
+		# Covariance Matrix for Tag measurements
+		self.Rtag = np.asmatrix(1.0e-6 * np.eye(4))
+		self.Rtag[3, 3] = 1.0e0
+
+		# Transition Matrix for Attitude measurements
+		self.Hatt = np.matrix(np.zeros((4, n)))
+		self.Hatt[0:4, 6:10] = np.matrix(np.eye(4))
+
+		# Covariance Matrix for Attitude measurements
+		self.Ratt = np.asmatrix(1.0e-9 * np.eye(4))
+
+		# Transition Matrix for IMU measurements
+		self.Himu = np.matrix(np.zeros((4, n)))
+		self.Himu[0:4, 10:14] = np.matrix(np.eye(4))
+
+		# Covariance Matrix for IMU measurements
+		self.Rimu = np.asmatrix(1.0e-6 * np.eye(4))
+
+		# Transition Matrix for Drone velocity measurements
+		self.HvelD = np.matrix(np.zeros((3, n)))
+		self.HvelD[0:3, 3:6] = np.matrix(np.eye(3))
+
+		# Covariance Matrix for Drone velocity measurements
+		self.RvelD = np.asmatrix(1.0e-5 * np.eye(3))
+
+		# Transition Matrix for Drone GPS measurements
+		self.HgpsD = np.matrix(np.zeros((3, n)))
+		self.HgpsD[0:3, 0:3] = np.matrix(np.eye(3))
+
+		# Covariance Matrix for Drone GPS measurements
+		self.RgpsD = np.asmatrix(1.0e-2 * np.eye(3))
+		self.RgpsD[2, 2] = 1.0
+
+		# Transition Matrix for Jetyak GPS measurements
+		self.HgpsJ = np.matrix(np.zeros((3, n)))
+		self.HgpsJ[0:3, 14:17] = np.matrix(np.eye(3))
 
-		# Setup Sensors
-		self.updateSensorR = True
-		self.tagS, self.velDS, self.gpsDS, self.gpsJS = setupSensors(n)
+		# Covariance Matrix for Jetyak GPS measurements
+		self.RgpsJ = np.asmatrix(1.0e-1 * np.eye(3))
+		self.RgpsJ[2, 2] = 1.0
 
-		# Attitude handles
-		self.droneAtti     = None
-		self.droneARates   = None
-		self.jetyakHeading = None
+		# Transition Matrix for Jetyak GPS heading
+		self.HhdgJ = np.matrix(np.zeros((1, n)))
+		self.HhdgJ[0, 19] = 1
+
+		# Covariance Matrix for Jetyak GPS heading
+		self.RhdgJ = np.matrix(1.0e-12)
+
+		# Process Noise Level
+		N = 5.0e-3
 
 		# Initialize Kalman Filter
 		self.fusionF = FusionEKF(F, P, N, self.rate)
@@ -92,9 +141,6 @@ class FilterNode():
 		self.jCompass_sub = rp.Subscriber("/jetyak2/global_position/compass_hdg", Float64, self.jCompass_callback, queue_size = 1)
 		self.tag_sub = rp.Subscriber("/jetyak_uav_vision/tag_pose", PoseStamped, self.tag_callback, queue_size = 1)
 
-		# Set up Services
-		self.resetFilter_srv = rp.Service("/jetyak_uav_vision/resetFilter", Trigger, self.resetFilter)
-
 		# Set up Publisher
 		self.state_pub = rp.Publisher("/jetyak_uav_vision/state", ObservedState, queue_size = 1)
 
@@ -102,109 +148,89 @@ class FilterNode():
 		t = threading.Thread(target=self.statePublisher)
 		t.start()
 
-		rp.spin()
-
-	def resetFilter(self, srv):
-		self.fusionF.resetFilter()
-
-		return TriggerResponse(True, "Filter reset")
-
-	def checkAngle(self, q):
-		while q < -np.pi:
-			q += 2 * np.pi
-
-		while q >= np.pi:
-			q -= 2 * np.pi
-		
-		return q
+		rp.spin()			
 
 	def dGPS_callback(self, msg):
 		if self.originSet:
 			enu = self.myENU.geo2enu(msg.latitude, msg.longitude, msg.altitude)
 
-			self.gpsDS.setZ(np.matrix([[enu.item(0)],[enu.item(1)],[enu.item(2)]]))
-			
-			r, P = self.fusionF.process(self.gpsDS)
-			
-			if self.updateSensorR:
-				self.gpsDS.updateR(r, P)
+			dGPSpoint = DataPoint()
+			dGPSpoint.setID('dgps')
+			dGPSpoint.setZ(np.matrix([[enu.item(0)],[enu.item(1)],[enu.item(2)]]))
+			self.fusionF.process(dGPSpoint, self.HgpsD, self.RgpsD)
 		else:
 			self.myENU.setENUorigin(msg.latitude, msg.longitude, msg.altitude)
 			self.originSet = True
+
+	def dAtti_callback(self, msg):
+		dAttiPoint = DataPoint()
+		dAttiPoint.setID('atti')
+		dAttiPoint.setZ(np.matrix([[msg.quaternion.x],
+								   [msg.quaternion.y],
+								   [msg.quaternion.z],
+								   [msg.quaternion.w]]))
+		self.fusionF.process(dAttiPoint, self.Hatt, self.Ratt)
+
+	def dIMU_callback(self, msg):
+		dIMUPoint = DataPoint()
+		dIMUPoint.setID('imu')
+		dIMUPoint.setZ(np.matrix([[msg.angular_velocity.x],
+								  [msg.angular_velocity.y],
+								  [msg.angular_velocity.z]]))
+		self.fusionF.process(dIMUPoint, self.Himu, self.Rimu)
 	
 	def dVel_callback(self, msg):
-		self.velDS.setZ(np.matrix([[msg.vector.x],
+		dVelPoint = DataPoint()
+		dVelPoint.setID('dvel')
+		dVelPoint.setZ(np.matrix([[msg.vector.x],
 								  [msg.vector.y],
 								  [msg.vector.z]]))
-		
-		r, P = self.fusionF.process(self.velDS)
-		
-		if self.updateSensorR:
-			self.velDS.updateR(r, P)
+		self.fusionF.process(dVelPoint, self.HvelD, self.RvelD)
 
 	def jGPS_callback(self, msg):
 		if self.originSet:
 			enu = self.myENU.geo2enu(msg.latitude, msg.longitude, msg.altitude)
 
-			self.gpsJS.setZ(np.matrix([[enu.item(0)],[enu.item(1)],[enu.item(2)]]))
-			
-			r, P = self.fusionF.process(self.gpsJS)
-			
-			if self.updateSensorR:
-				self.gpsJS.updateR(r, P)
-
-	def tag_callback(self, msg):
-		if (self.droneAtti is not None) and (self.jetyakHeading is not None):
-			tagPos = Quaternion(msg.pose.position.x,
-								msg.pose.position.y,
-								msg.pose.position.z,
-								0)
-			
-			qTag = Quaternion(msg.pose.orientation.x,
-							  msg.pose.orientation.y,
-							  msg.pose.orientation.z,
-							  msg.pose.orientation.w)
-			
-			posWq = quatMultiply(quatMultiply(self.droneAtti, tagPos), quatInverse(self.droneAtti))				
-			rpyT = quat2rpy(qTag)
-			rpyD = quat2rpy(self.droneAtti)
-
-			offq = self.checkAngle(self.jetyakHeading - rpyT[2] - rpyD[2])
-					
-			self.tagS.setZ(np.matrix([[posWq.x],
-									  [posWq.y],
-									  [posWq.z],
-									  [offq]]))
-			
-			r, P = self.fusionF.process(self.tagS)
-			
-			if self.updateSensorR:
-					self.tagS.updateR(r, P)
-	
-	def dAtti_callback(self, msg):
-		self.droneAtti = Quaternion(msg.quaternion.x,
-									msg.quaternion.y,
-									msg.quaternion.z,
-									msg.quaternion.w)
-
-	def dIMU_callback(self, msg):
-		self.droneARates = np.matrix([[msg.angular_velocity.x],
-								  	  [msg.angular_velocity.y],
-								  	  [msg.angular_velocity.z]])
+			jGPSpoint = DataPoint()
+			jGPSpoint.setID('jgps')
+			jGPSpoint.setZ(np.matrix([[enu.item(0)],[enu.item(1)],[enu.item(2)]]))
+			self.fusionF.process(jGPSpoint, self.HgpsJ, self.RgpsJ)
 
 	def jCompass_callback(self, msg):
+		jHeadingPoint = DataPoint()
+		jHeadingPoint.setID('jhdg')
 		if msg.data < 270:
-			self.jetyakHeading = np.matrix([np.deg2rad(90 - msg.data)])
+			jHeadingPoint.setZ(np.matrix([np.deg2rad(90 - msg.data)]))
 		else:
-			self.jetyakHeading = np.matrix([np.deg2rad(450 - msg.data)])
+			jHeadingPoint.setZ(np.matrix([np.deg2rad(450 - msg.data)]))
+		self.fusionF.process(jHeadingPoint, self.HhdgJ, self.RhdgJ)
+
+	def tag_callback(self, msg):
+		tagPoint = DataPoint()
+		tagPoint.setID('tag')
+		tagPoint.setZ(np.matrix([[msg.pose.position.x],
+								 [msg.pose.position.y],
+								 [msg.pose.position.z],
+								 [msg.pose.orientation.x],
+								 [msg.pose.orientation.y],
+								 [msg.pose.orientation.z],
+								 [msg.pose.orientation.w]]))
+		tagPoint.setTime(msg.header.stamp.to_sec())
+		if self.tagFilter(tagPoint):
+			self.fusionF.process(tagPoint, self.Htag, self.Rtag)
+			self.lastTag = tagPoint
 	
 	def statePublisher(self):
 		r = rp.Rate(self.rate)
 		while not rp.is_shutdown():
 			X = self.fusionF.getState()
 
-			if not (X is None):
-				rpy = quat2rpy(self.droneAtti)
+			if X != None:
+				q = Quaternion(X.item(6), X.item(7), X.item(8), X.item(9))
+				dq = Quaternion(X.item(10), X.item(11), X.item(12), X.item(13))
+
+				omega = quatMultiply(quatInverse(q), dq)
+				rpy = quat2rpy(q)
 
 				stateMsg = ObservedState()
 				stateMsg.header.stamp = rp.Time.now()
@@ -222,25 +248,19 @@ class FilterNode():
 				stateMsg.drone_q.y = rpy[1]
 				stateMsg.drone_q.z = rpy[2]
 
-				stateMsg.drone_qdot.x = self.droneARates[0]
-				stateMsg.drone_qdot.y = self.droneARates[1]
-				stateMsg.drone_qdot.z = self.droneARates[2]
+				stateMsg.drone_qdot.x = 2 * omega.x
+				stateMsg.drone_qdot.y = 2 * omega.y
+				stateMsg.drone_qdot.z = 2 * omega.z
 
-				stateMsg.boat_p.x = X.item(6) - X.item(11)
-				stateMsg.boat_p.y = X.item(7) - X.item(12)
-				stateMsg.boat_p.z = X.item(8) - X.item(13)
+				stateMsg.boat_p.x = X.item(14) - X.item(20)
+				stateMsg.boat_p.y = X.item(15) - X.item(21)
+				stateMsg.boat_p.z = X.item(16) - X.item(22)
 
-				stateMsg.boat_pdot.x = X.item(9)
-				stateMsg.boat_pdot.y = X.item(10)
+				stateMsg.boat_pdot.x = X.item(17)
+				stateMsg.boat_pdot.y = X.item(18)
 				stateMsg.boat_pdot.z = 0
 
-				stateMsg.heading = self.checkAngle(self.jetyakHeading - X.item(14))
-
-				stateMsg.gps_offset.x = X.item(11)
-				stateMsg.gps_offset.y = X.item(12)
-				stateMsg.gps_offset.z = X.item(13)
-
-				stateMsg.heading_offset = X.item(14)
+				stateMsg.heading = X.item(19) - X.item(23)
 
 				stateMsg.origin.x = self.myENU.latZero
 				stateMsg.origin.y = self.myENU.lonZero
@@ -249,6 +269,26 @@ class FilterNode():
 				self.state_pub.publish(stateMsg)
 			
 			r.sleep()
+	
+	def tagFilter(self, newTag):
+		if (self.lastTag.getTime() == None):
+			return True
+		else:
+			dt = newTag.getTime() - self.lastTag.getTime()
+			dX = newTag.getZ().item(0) - self.lastTag.getZ().item(0)
+			dY = newTag.getZ().item(1) - self.lastTag.getZ().item(1)
+			dZ = newTag.getZ().item(2) - self.lastTag.getZ().item(2)
+
+			v = np.sqrt(pow(dX, 2) + pow(dY, 2) + pow(dZ, 2)) / dt
+
+			rpyLast = quat2rpy(Quaternion(self.lastTag.getZ().item(3), self.lastTag.getZ().item(4), self.lastTag.getZ().item(5), self.lastTag.getZ().item(6)))
+			rpyNow  = quat2rpy(Quaternion(newTag.getZ().item(3), newTag.getZ().item(4), newTag.getZ().item(5), newTag.getZ().item(6)))
+			dYaw = np.absolute(rpyLast[2] - rpyNow[2]) / dt
+
+			if (v < 5.0 and dYaw < 1.0):
+				return True
+			else:
+				return False
 
 # Start Node
 filtered = FilterNode()
diff --git a/scripts/nodes/filter/fusion_ekf.py b/scripts/nodes/filter/fusion_ekf.py
index fe0a9eb..ba83964 100755
--- a/scripts/nodes/filter/fusion_ekf.py
+++ b/scripts/nodes/filter/fusion_ekf.py
@@ -26,7 +26,7 @@ Author: Michail Kalaitzakis
 """
 import numpy as np
 from kalman_filter import KalmanFilter
-from sensor import Sensor
+from data_point import DataPoint
 
 from quaternion import Quaternion
 from quaternion import quatMultiply
@@ -61,8 +61,9 @@ class FusionEKF:
 		self.isInit    = False		
 
 		self.X[0:3]    = np.nan  # Drone's position
+		self.X[6:10]   = np.nan  # Drone's attitude
 		self.X[14:17]  = np.nan  # Jetyak's position
-		self.X[19:24]  = np.nan  # Jetyak's GPS and heading offset
+		self.X[19:24]  = np.nan  # Jetyak's heading and GPS offset
 
 	def initialize(self, dataPoint):
 		if dataPoint.getID() == 'dgps':
@@ -70,17 +71,43 @@ class FusionEKF:
 			self.X[1] = dataPoint.getZ().item(1)
 			self.X[2] = dataPoint.getZ().item(2)
 		elif dataPoint.getID() == 'jgps':
+			self.X[14] = dataPoint.getZ().item(0)
+			self.X[15] = dataPoint.getZ().item(1)
+			self.X[16] = dataPoint.getZ().item(2)
+		elif dataPoint.getID() == 'atti':
 			self.X[6] = dataPoint.getZ().item(0)
 			self.X[7] = dataPoint.getZ().item(1)
 			self.X[8] = dataPoint.getZ().item(2)
+			self.X[9] = dataPoint.getZ().item(3)
+		elif dataPoint.getID() == 'jhdg':
+			self.X[19] = dataPoint.getZ().item(0)
 		elif dataPoint.getID() == 'tag':
 			if (not (np.isnan(self.X[0]) or 
-					 np.isnan(self.X[6]))):
-
-				self.X[11] = self.X[6] - self.X[0] - dataPoint.getZ().item(0)
-				self.X[12] = self.X[7] - self.X[1] - dataPoint.getZ().item(1)
-				self.X[13] = self.X[8] - self.X[2] - dataPoint.getZ().item(2)
-				self.X[14] = dataPoint.getZ().item(3)
+					 np.isnan(self.X[6]) or
+					 np.isnan(self.X[14]) or
+					 np.isnan(self.X[19]))):
+
+				q = Quaternion(self.X[6], self.X[7], self.X[8], self.X[9])
+
+				tagPos = Quaternion(dataPoint.getZ().item(0),
+									dataPoint.getZ().item(1),
+									dataPoint.getZ().item(2),
+									0)
+				
+				qT = Quaternion(dataPoint.getZ().item(3),
+								dataPoint.getZ().item(4),
+								dataPoint.getZ().item(5),
+								dataPoint.getZ().item(6))
+				
+				rpyT = quat2rpy(qT)
+				rpyD = quat2rpy(q)
+				
+				posWq = quatMultiply(quatMultiply(q, tagPos), quatInverse(q))
+
+				self.X[20] = self.X[14] - self.X[0] - posWq.x
+				self.X[21] = self.X[15] - self.X[1] - posWq.y
+				self.X[22] = self.X[16] - self.X[2] - posWq.z
+				self.X[23] = self.X[19] - rpyD[2] - rpyT[2]
 
 				self.kalmanF.initialize(self.X, self.F, self.P, self.N)
 				self.kalmanF.updateF(self.dt)
@@ -90,36 +117,70 @@ class FusionEKF:
 
 				print 'Colocalization filter initialized'
 
-	def process(self, dataPoint):
+	def process(self, dataPoint, H, R):
 		if not self.isInit:
 			self.initialize(dataPoint)
-
-			return None, None
 		else:
-			r = None
-			P = None
-
 			# KF Correction Step
-			r, P = self.kalmanF.correct(dataPoint.getZ(), dataPoint.getH(), dataPoint.getR(), dataPoint.getChi())
+			if dataPoint.getID() == 'tag':
+				q = Quaternion(self.X.item(6),
+							   self.X.item(7),
+							   self.X.item(8),
+							   self.X.item(9))
+
+				tagPos = Quaternion(dataPoint.getZ().item(0),
+									dataPoint.getZ().item(1),
+									dataPoint.getZ().item(2),
+									0)
+				
+				qTag = Quaternion(dataPoint.getZ().item(3),
+								  dataPoint.getZ().item(4),
+								  dataPoint.getZ().item(5),
+								  dataPoint.getZ().item(6))
+
+				posWq = quatMultiply(quatMultiply(q, tagPos), quatInverse(q))				
+				rpyT = quat2rpy(qTag)
+				rpyD = quat2rpy(q)
+
+				byaw = rpyT[2] + rpyD[2]
+				if byaw > np.pi:
+					byaw = np.pi
+				elif byaw < - np.pi:
+					byaw = -np.pi
+				
+				posW = np.matrix([[posWq.x],
+								  [posWq.y],
+								  [posWq.z],
+								  [byaw]])
+
+				self.kalmanF.correct(posW, H, R)
+			elif dataPoint.getID() == 'imu':
+				q = Quaternion(self.X.item(6),
+							   self.X.item(7),
+							   self.X.item(8),
+							   self.X.item(9))
+
+				qOmega = Quaternion(dataPoint.getZ().item(0),
+									dataPoint.getZ().item(1),
+									dataPoint.getZ().item(2),
+									0)
+
+				dq = quatMultiply(q, qOmega)
+
+				dqm = np.matrix([[0.5 * dq.x],
+								 [0.5 * dq.y],
+								 [0.5 * dq.z],
+								 [0.5 * dq.w]])
+					
+				self.kalmanF.correct(dqm, H, R)
+			else:
+				self.kalmanF.correct(dataPoint.getZ(), H, R)
 			
-			if r is None:
-				print "A ", dataPoint.getID(), " measurement was rejected"
-
 			self.X = self.kalmanF.getState()
 
-			return r, P
-
 	def getState(self):
 		if self.isInit:
 			self.kalmanF.predict()
 			return self.X
 		else:
 			return None
-
-	def resetFilter(self):
-		self.isInit    = False
-
-		self.X         = np.matrix(np.zeros((self.n, 1)))
-		self.X[0:3]    = np.nan  # Drone's position
-		self.X[14:17]  = np.nan  # Jetyak's position
-		self.X[19:24]  = np.nan  # Jetyak's GPS and heading offset
diff --git a/scripts/nodes/filter/kalman_filter.py b/scripts/nodes/filter/kalman_filter.py
index 9e731ab..5cd73b3 100755
--- a/scripts/nodes/filter/kalman_filter.py
+++ b/scripts/nodes/filter/kalman_filter.py
@@ -55,49 +55,54 @@ class KalmanFilter:
 		self.N = N
 		self.n = np.shape(F)[0]
 
-		diagCf = np.array([1e-1, 1e-1, 1e-1,
+		diagCf = np.array([1e-1, 1e-1, 1e1,
 		 				   1e0, 1e0, 1e0,
-		 				   1e-1, 1e-1, 1e-3,
+		 				   1e0, 1e0, 1e0, 1e0,
+		 				   1e0, 1e0, 1e0, 1e0,
+		 				   1e0, 1e0, 1e-3,
 		 				   1e0, 1e0,
+		 				   1e0,
 		 				   1e0, 1e0, 1e0,
-		 				   1e-1])
+		 				   1e-3])
 		self.Cf = np.diag(diagCf)
 
 	def updateQ(self):
 		self.Q = self.F * self.Cf * self.F.T * self.N
 	
 	def updateF(self, dt):
-		self.F[0:3,  3:6] = np.matrix(dt * np.eye(3))
-		self.F[6:8, 9:11] = np.matrix(dt * np.eye(2))
+		self.F[  0:3,   3:6] = np.matrix(dt * np.eye(3))
+		self.F[14:16, 17:19] = np.matrix(dt * np.eye(2))
 
 	def predict(self):
 		self.X = self.F * self.X
+		self.checkQuaternion()
 		self.P = self.F * self.P * self.F.T + self.Q
 		self.P = (self.P + self.P.T) / 2
 
-	def correct(self, z, H, R, chiCritical):
+	def correct(self, z, H, R):
 		hatP = self.P * H.T
 		S    = H * hatP + R
 		K    = hatP * S.I
 		I    = np.asmatrix(np.eye(self.n))
 
-		# Check residual and apply chi-squared outlier rejection
-		r = np.asmatrix((z - H * self.X))
-		chi2 = r.T * S.I * r
-
-		if chi2 < chiCritical:
-			self.X = self.X + K * (z - H * self.X)
-			self.P = (I - K * H) * self.P
-			self.P = (self.P + self.P.T) / 2
+		self.X = self.X + K * (z - H * self.X)
+		self.checkQuaternion()
+		self.P = (I - K * H) * self.P
+		self.P = (self.P + self.P.T) / 2
+	
+	def checkQuaternion(self):
+		qx = self.X.item(6)
+		qy = self.X.item(7)
+		qz = self.X.item(8)
+		qw = self.X.item(9)
 
-			Pz = H * self.P * H.T
+		mag = pow(pow(qx,2) + pow(qy,2) + pow(qz,2) + pow(qw,2), 0.5)
 
-			return r, Pz
-		else:
-			return None, None
+		if mag > 0:
+			self.X.item(6) / mag
+			self.X.item(7) / mag
+			self.X.item(8) / mag
+			self.X.item(9) / mag
 
 	def getState(self):
 		return self.X
-	
-	def getP(self):
-		return self.P.diagonal()
\ No newline at end of file
diff --git a/scripts/nodes/filter/sensor.py b/scripts/nodes/filter/sensor.py
deleted file mode 100644
index 0dae25a..0000000
--- a/scripts/nodes/filter/sensor.py
+++ /dev/null
@@ -1,62 +0,0 @@
-import numpy as np
-
-class Sensor:
-	"""
-		Sensor class
-
-		Handles the sensor data and measurements
-		Updates R matrix using the residuals
-	"""
-
-	def __init__(self, ID, Rnom, H, N, chiCritical):
-		self.ID   = ID
-		self.R    = Rnom
-		self.H    = H
-		self.N    = N
-		self.Rnom = Rnom
-		self.chiC = chiCritical
-
-		self.residuals = None
-		self.Z         = None
-	
-	def setZ(self, measurement):
-		self.Z = measurement
-	
-	def getID(self):
-		return self.ID
-	
-	def getZ(self):
-		return self.Z
-	
-	def getChi(self):
-		return self.chiC
-	
-	def getR(self):
-		return self.R
-	
-	def getH(self):
-		return self.H
-	
-	def updateR(self, r, P):
-		if (r is not None) and (P is not None):
-			if self.residuals is None:
-				self.residuals = np.transpose(r)
-			elif self.residuals.shape[0] < self.N:
-				self.residuals = np.concatenate((self.residuals, np.transpose(r)), axis = 0)
-			else:
-				self.residuals = np.concatenate((self.residuals[1:], np.transpose(r)), axis = 0)
-			
-			if self.residuals.shape[0] == self.N:
-				res = np.asmatrix(self.residuals)
-				hatRdiag = np.array(np.diagonal(((res.T * res) / self.N) - P))
-
-				for i in range(hatRdiag.shape[0]):
-					if hatRdiag[i] < self.Rnom[i,i]:
-						hatRdiag[i] = self.Rnom[i,i]
-				
-				# if self.ID == 'jgps':
-				# 	print "Residuals: ", r
-				# 	print "P: ", P
-				# 	print "New R: ", np.diag(hatRdiag)
-
-				self.R = np.diag(hatRdiag)
diff --git a/scripts/nodes/filter/setupSensors.py b/scripts/nodes/filter/setupSensors.py
deleted file mode 100644
index 217d631..0000000
--- a/scripts/nodes/filter/setupSensors.py
+++ /dev/null
@@ -1,46 +0,0 @@
-import numpy as np
-from sensor import Sensor
-
-def setupSensors(n):
-	# Critical chi-squared values for P = 0.001 and different degrees of freedom
-	chiSquared_1 = 10.828
-	chiSquared_3 = 16.266
-	
-	# Transition Matrix for Tag measurements
-	Htag = np.matrix(np.zeros((4, n)))
-	Htag[0:3,   0:3] = np.matrix(-1 * np.eye(3))
-	Htag[0:3,   6:9] = np.matrix(np.eye(3))
-	Htag[0:3, 11:14] = np.matrix(-1 * np.eye(3))
-	Htag[3,      14] = 1
-
-	# Covariance Matrix for Tag measurements
-	Rtag = np.asmatrix(1.0e-3 * np.eye(4))
-
-	# Transition Matrix for Drone velocity measurements
-	HvelD = np.matrix(np.zeros((3, n)))
-	HvelD[0:3, 3:6] = np.matrix(np.eye(3))
-
-	# Covariance Matrix for Drone velocity measurements
-	RvelD = np.asmatrix(1.0e-3 * np.eye(3))
-
-	# Transition Matrix for Drone GPS measurements
-	HgpsD = np.matrix(np.zeros((3, n)))
-	HgpsD[0:3, 0:3] = np.matrix(np.eye(3))
-
-	# Covariance Matrix for Drone GPS measurements
-	RgpsD = np.asmatrix(1.0e-1 * np.eye(3))
-
-	# Transition Matrix for Jetyak GPS measurements
-	HgpsJ = np.matrix(np.zeros((3, n)))
-	HgpsJ[0:3, 6:9] = np.matrix(np.eye(3))
-
-	# Covariance Matrix for Jetyak GPS measurements
-	RgpsJ = np.asmatrix(5.0e0 * np.eye(3))
-
-	# Setup sensors
-	tagS  = Sensor('tag',  Rtag,  Htag,   39.0, chiSquared_3)
-	velDS = Sensor('dvel', RvelD, HvelD, 150.0, chiSquared_1)
-	gpsDS = Sensor('dgps', RgpsD, HgpsD, 150.0, chiSquared_1)
-	gpsJS = Sensor('jgps', RgpsJ, HgpsJ,  10.0, chiSquared_1)
-
-	return (tagS, velDS, gpsDS, gpsJS)
\ No newline at end of file
diff --git a/scripts/nodes/optiStatePub.py b/scripts/nodes/optiStatePub.py
index e2ab0af..5a9abc5 100755
--- a/scripts/nodes/optiStatePub.py
+++ b/scripts/nodes/optiStatePub.py
@@ -14,31 +14,25 @@ class StatePub():
 
 		rp.init_node("lqr_test")
 
-		self.optiSub = rp.Subscriber("vrpn_client_node/Matrice/pose",PoseStamped,self.optiCB,queue_size=1)
-		self.boatOptiSub = rp.Subscriber("vrpn_client_node/MasterTag/pose",PoseStamped,self.boatCB,queue_size=1)
-		self.velSub=rp.Subscriber("/dji_sdk/velocity",Vector3Stamped,self.velCB,queue_size=1)
-		self.imuSub=rp.Subscriber("/dji_sdk/imu",Imu,self.imuCB,queue_size=1)
-		#self.rcSub=rp.Subscriber("/dji_sdk/rc",Joy,self.rcCB,queue_size=1)
+
+		self.optiSub = rp.Subscriber("vrpn_client_node/Matrice/pose",PoseStamped,self.optiCB)
+		self.boatOptiSub = rp.Subscriber("vrpn_client_node/MasterTag/pose",PoseStamped,self.boatCB)
+		self.velSub=rp.Subscriber("/dji_sdk/velocity",Vector3Stamped,self.velCB)
+		self.imuSub=rp.Subscriber("/dji_sdk/imu",Imu,self.imuCB)
 		self.statePub=rp.Publisher("/jetyak_uav_vision/state",ObservedState,queue_size=1)
 		self.state = ObservedState()
-		self.lastOpti=[0,0,0,0]
-		self.lastOptiT=rp.Time.now().to_sec()
 		rp.spin()
-
 	def publish(self,):
-		#self.lastOpti= [self.state.drone_p.x, self.state.drone_p.y, self.state.drone_p.z, self.lastOptiT]
-
 		self.state.header.stamp = rp.Time.now()
 		self.statePub.publish(self.state)
-		
-	#def rcCB(self,msg):
-	#	self.publish()
+
+
 	def imuCB(self,msg):
 		self.state.drone_qdot.x=msg.angular_velocity.x
 		self.state.drone_qdot.y=msg.angular_velocity.y
 		self.state.drone_qdot.z=msg.angular_velocity.z
+		self.publish()
 
-	
 	def velCB(self,msg):
 		self.state.drone_pdot.x=msg.vector.x
 		self.state.drone_pdot.y=msg.vector.y
@@ -50,34 +44,20 @@ class StatePub():
 		self.state.boat_p.y=msg.pose.position.y
 		self.state.boat_p.z=msg.pose.position.z
 
-		(r,p,y) =euler_from_quaternion([msg.pose.orientation.x, msg.pose.orientation.y, msg.pose.orientation.z, msg.pose.orientation.w])
+		(r,p,y) =euler_from_quaternion([msg.pose.orientation.x,msg.pose.orientation.y,msg.pose.orientation.z,msg.pose.orientation.w])
 		self.state.heading=y
-
+		self.publish()
 
 	def optiCB(self,msg):
+		self.state.drone_p.x=msg.pose.position.x
+		self.state.drone_p.y=msg.pose.position.y
+		self.state.drone_p.z=msg.pose.position.z
+
 		(r,p,y) =euler_from_quaternion([msg.pose.orientation.x,msg.pose.orientation.y,msg.pose.orientation.z,msg.pose.orientation.w])
 		self.state.drone_q.x=r
 		self.state.drone_q.y=p
 		self.state.drone_q.z=y
 		self.yaw=y
-		"""
-		dt=msg.header.stamp.to_sec()-self.lastOpti[3]
-		self.lastOptiT=msg.header.stamp.to_sec()
-		dx=(msg.pose.position.x-self.lastOpti[0])/dt
-		dy=(msg.pose.position.y-self.lastOpti[1])/dt
-		dz=(msg.pose.position.z-self.lastOpti[2])/dt
-
-		tx=dx*math.cos(-y)-dy*math.sin(-y)
-		ty=dx*math.sin(-y)+dy*math.cos(-y)
-		#print("%1.8f,\t%1.8f,\t%1.8f"%(tx,ty,dt))
-		
-		self.state.drone_pdot.x=tx
-		self.state.drone_pdot.y=ty
-		self.state.drone_pdot.z=dz
-		"""
-		self.state.drone_p.x=msg.pose.position.x
-		self.state.drone_p.y=msg.pose.position.y
-		self.state.drone_p.z=msg.pose.position.z
-
+		self.publish()
 
 lll = StatePub()
diff --git a/scripts/nodes/rc_interpreter.py b/scripts/nodes/rc_interpreter.py
index f18e118..ad669bd 100755
--- a/scripts/nodes/rc_interpreter.py
+++ b/scripts/nodes/rc_interpreter.py
@@ -31,7 +31,6 @@ Author: Brennan Cain
 import rospy as rp
 from mavros_msgs.msg import RCIn
 from jetyak_uav_utils.srv import SetString
-from std_srvs.srv import Trigger
 
 
 class RC_Interpreter():
@@ -54,8 +53,6 @@ class RC_Interpreter():
 		self.joySub = rp.Subscriber("/jetyak2/rc/in", RCIn, self.joyCallback)
 		rp.wait_for_service("/jetyak_uav_utils/setMode")
 		self.modeClient=rp.ServiceProxy("/jetyak_uav_utils/setMode", SetString)
-		rp.wait_for_service("/jetyak_uav_utils/create_spiral")
-		self.spiralClient=rp.ServiceProxy("/jetyak_uav_utils/create_spiral", Trigger)
 		rp.spin()
 
 	def joyCallback(self, msg):
@@ -69,9 +66,6 @@ class RC_Interpreter():
 			#print("Mode: %s, \tpart: %i" % (self.modeTable[part],part))
 			while(not self.modeClient(self.modeTable[part])):
 				print("Trying to change to %s"%self.modeTable[part])
-		if part==5:
-			self.spiralClient()
-			print("spiralGen")
 
 if __name__ == "__main__":
 	rc=RC_Interpreter(900, 2000, 9) # min, max, sections
diff --git a/scripts/nodes/waypoint_follow.py b/scripts/nodes/waypoint_follow.py
index c7209a9..0cc6fb1 100755
--- a/scripts/nodes/waypoint_follow.py
+++ b/scripts/nodes/waypoint_follow.py
@@ -184,7 +184,7 @@ class WaypointFollow():
 		self.wps = []
 
 		d_desired = .5
-		wp_radius = 3
+		wp_radius = 2
 		turns = 4
 
 		initial_r = wp_radius
@@ -210,7 +210,7 @@ class WaypointFollow():
 		for i in range(len(x)):
 			print((x[i],y[i]))
 			wp = Waypoint()
-			wp.alt = 15
+			wp.alt = 10
 			wp.lat = self.pose[1] + y[i]
 			wp.lon = self.pose[0] + x[i]
 
diff --git a/src/behaviors_behaviors.cpp b/src/behaviors_behaviors.cpp
index 369ede7..6c851da 100644
--- a/src/behaviors_behaviors.cpp
+++ b/src/behaviors_behaviors.cpp
@@ -29,11 +29,6 @@ SOFTWARE.
  */
 
 #include "jetyak_uav_utils/behaviors.h"
-
-float clip(float x, float low, float high) {
-	return x>high ? high : (x<low?low:x);
-}
-
 void Behaviors::takeoffBehavior()
 {
 	if (!propellorsRunning)
@@ -56,7 +51,7 @@ void Behaviors::takeoffBehavior()
 
 void Behaviors::followBehavior()
 {
-	if (ros::Time::now().toSec() - lastSpotted <= 10) // TODO: Add tag loss threshold for follow_
+	if (ros::Time::now().toSec() - lastSpotted <= 5 || true) // TODO: Add tag loss threshold for follow_
 	{
 		// Get the setpoint in the drone FLU
 		Eigen::Vector4d goal_b;
@@ -92,8 +87,6 @@ void Behaviors::followBehavior()
 
 void Behaviors::leaveBehavior()
 {
-	leave_.input.axes[0]=clip(leave_.input.axes[0],-.1,.1);
-	leave_.input.axes[1]=clip(leave_.input.axes[1],-.1,.1);
 	cmdPub_.publish(leave_.input);
 }
 
@@ -136,8 +129,8 @@ void Behaviors::returnBehavior()
 			cmdPub_.publish(cmd);
 		}
 	}
-	else if (return_.stage == return_.SETTLE and ros::Time::now().toSec() - lastSpotted > return_.tagLossThresh)
-	{	
+	else if (return_.stage == return_.SETTLE and ros::Time::now().toSec() - state.header.stamp.toSec() > return_.tagLossThresh)
+	{
 		ROS_WARN("Tag lost for %1.2f seconds, going back up", ros::Time::now().toSec() - state.header.stamp.toSec());
 		return_.stage = return_.UP;
 	}
@@ -174,8 +167,8 @@ void Behaviors::returnBehavior()
 
 			Eigen::Vector4d cmdM = lqr_->getCommand(set);
 			sensor_msgs::Joy cmd;
-			cmd.axes.push_back(clip(cmdM(0),-.1,.1));
-			cmd.axes.push_back(clip(cmdM(1),-.1,.1));
+			cmd.axes.push_back(cmdM(0));
+			cmd.axes.push_back(cmdM(1));
 			cmd.axes.push_back(cmdM(2));
 			cmd.axes.push_back(cmdM(3));
 			cmd.axes.push_back(JETYAK_UAV_UTILS::LQR);
@@ -229,10 +222,10 @@ void Behaviors::returnBehavior()
 
 		Eigen::Vector4d cmdM = lqr_->getCommand(set);
 		sensor_msgs::Joy cmd;
-			cmd.axes.push_back(clip(cmdM(0),-.1,.1));
-			cmd.axes.push_back(clip(cmdM(1),-.1,.1));
-			cmd.axes.push_back(cmdM(2));
-			cmd.axes.push_back(cmdM(3));
+		cmd.axes.push_back(cmdM(0));
+		cmd.axes.push_back(cmdM(1));
+		cmd.axes.push_back(cmdM(2));
+		cmd.axes.push_back(cmdM(3));
 		cmd.axes.push_back(JETYAK_UAV_UTILS::LQR);
 		cmdPub_.publish(cmd);
 	}
@@ -259,7 +252,7 @@ void Behaviors::landBehavior()
 		Eigen::Vector2d vBoat(state.boat_pdot.x, state.boat_pdot.y);				 // Boat velocity in world frame
 		vBoat = bsc_common::util::rotation_matrix(-state.drone_q.z) * vBoat; // Boat velocity in drone frame
 
-		if (ros::Time::now().toSec() - lastSpotted <= 3)
+		if (ros::Time::now().toSec() - lastSpotted <= 3 or true)
 		{
 
 			if (inLandThreshold())
@@ -275,10 +268,10 @@ void Behaviors::landBehavior()
 			}
 			else
 			{
-				double vMult = clip(1-fabs(goal_d(0))/fabs(follow_.goal_pose.x-land_.goal_pose.x),0,1);
+
 				Eigen::Matrix<double, 12, 1> set;
 				set << goal_d(0), goal_d(1), goal_d(2), // Position setpoint (xyz)
-						vBoat(0)*vMult,0, 0,				// Velocity setpoint (xyz)
+						vBoat(0, 0), vBoat(1, 0), 0,				// Velocity setpoint (xyz)
 						0, 0, goal_d(3),										// Angle setpoint (rpy)
 						0, 0, 0;														// Angular velocity setpoint (rpy)
 
@@ -329,4 +322,4 @@ void Behaviors::hoverBehavior()
 	cmd.axes.push_back(0);
 	cmd.axes.push_back(JETYAK_UAV_UTILS::WORLD_RATE);
 	cmdPub_.publish(cmd);
-}
+};
diff --git a/src/behaviors_common.cpp b/src/behaviors_common.cpp
index 620a1d7..ee38087 100644
--- a/src/behaviors_common.cpp
+++ b/src/behaviors_common.cpp
@@ -228,7 +228,6 @@ bool Behaviors::inLandThreshold()
 
 	double xl = (z - zb) * (xb - xt) / (zt - zb) - xb;
 	double xh = (z - zb) * (xt - xb) / (zt - zb) + xb;
-
 	double yl = (z - zb) * (yb - yt) / (zt - zb) - yb;
 	double yh = (z - zb) * (yt - yb) / (zt - zb) + yb;
 
@@ -236,15 +235,10 @@ bool Behaviors::inLandThreshold()
 	bool inY = yl < y and y < yh;
 	bool inZ = zb < z and z < zt;
 	bool inW = fabs(w) < land_.angleThresh;
-
-	double velSqr = pow(state.drone_pdot.x-state.boat_pdot.x, 2) + pow(state.drone_pdot.y-state.boat_pdot.y, 2);
-	bool inVel = velSqr < land_.velThreshSqr;
+	bool inVel = (pow(state.drone_pdot.x-state.boat_pdot.x, 2) + pow(state.drone_pdot.y-state.boat_pdot.y, 2)) < land_.velThreshSqr;
 	// ROS_WARN("%1.8f,%1.8f",(pow(state.drone_pdot.x, 2) + pow(state.drone_pdot.y, 2)),land_.velThreshSqr);
 	ROS_WARN("%s,%s,%s,%s,%s",inX?" true":"false",inY?" true":"false",inZ?" true":"false",inW?" true":"false",inVel?" true":"false");
 	ROS_WARN("X %1.2f<%1.2f<%1.2f",xl,x,xh);
 	ROS_WARN("Y %1.2f<%1.2f<%1.2f",yl,y,yh);
-	ROS_WARN("Z %1.2f<%1.2f<%1.2f",zb,z,zt);
-	ROS_WARN("W %1.2f<%1.2f<%1.2f",-land_.angleThresh,w,land_.angleThresh);
-	ROS_WARN("V %1.2f<%1.2f",sqrt(velSqr),sqrt(land_.velThreshSqr));
 	return inX and inY and inZ and inW and inVel;
 }
diff --git a/src/gimbal_tag.cpp b/src/gimbal_tag.cpp
index b0c75fc..16d07ec 100644
--- a/src/gimbal_tag.cpp
+++ b/src/gimbal_tag.cpp
@@ -102,30 +102,34 @@ void gimbal_tag::tagCallback(const ar_track_alvar_msgs::AlvarMarkers &msg)
 {
 	if (!msg.markers.empty())
 	{
-		// Pass the ar_pose as a vector3 for the dji_gimbal
-		geometry_msgs::Vector3 arVec3;
-		arVec3.x = msg.markers[0].pose.pose.position.x;
-		arVec3.y = msg.markers[0].pose.pose.position.y;
-		arVec3.z = msg.markers[0].pose.pose.position.z;
-		tagPosePub.publish(arVec3);
-
-		// Update Tag quaternion
-		tf::quaternionMsgToTF(msg.markers[0].pose.pose.orientation, qTag);
-		qTag.normalize();
-
-		// Update Tag position as quaternion
-		posTag[0] = msg.markers[0].pose.pose.position.x;
-		posTag[1] = msg.markers[0].pose.pose.position.y;
-		posTag[2] = msg.markers[0].pose.pose.position.z;
-		posTag[3] = 0;
-
-		// Go from Camera frame to Gimbal frame
-		qTag = qFix * qTag;
-
-		posTag = qCamera2Gimbal.inverse() * posTag * qCamera2Gimbal;
-
-		tagFound = true;
-		publishTagPose();
+		// Check that z axis is not flipped
+		if (msg.markers[0].pose.pose.position.z > 0)
+		{
+			// Pass the ar_pose as a vector3 for the dji_gimbal
+			geometry_msgs::Vector3 arVec3;
+			arVec3.x = msg.markers[0].pose.pose.position.x;
+			arVec3.y = msg.markers[0].pose.pose.position.y;
+			arVec3.z = msg.markers[0].pose.pose.position.z;
+			tagPosePub.publish(arVec3);
+
+			// Update Tag quaternion
+			tf::quaternionMsgToTF(msg.markers[0].pose.pose.orientation, qTag);
+			qTag.normalize();
+
+			// Update Tag position as quaternion
+			posTag[0] = msg.markers[0].pose.pose.position.x;
+			posTag[1] = msg.markers[0].pose.pose.position.y;
+			posTag[2] = msg.markers[0].pose.pose.position.z;
+			posTag[3] = 0;
+
+			// Go from Camera frame to Gimbal frame
+			qTag = qFix * qTag;
+
+			posTag = qCamera2Gimbal.inverse() * posTag * qCamera2Gimbal;
+
+			tagFound = true;
+			publishTagPose();
+		}
 	}
 	else
 		tagFound = false;
